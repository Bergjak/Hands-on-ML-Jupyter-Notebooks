{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b77d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklear.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97bc4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "# Max entry is 255\n",
    "X_train_full, X_test = X_train_full/255, X_test/255\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc23a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3), (40000, 1), (10000, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c24adaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(BN: bool, lr, neurons: int, layerz: int, activation: str, initializer: str):\n",
    "    model = keras.Sequential([keras.layers.Flatten(input_shape=(32, 32, 3))])\n",
    "    for _ in range(layerz):\n",
    "        if BN: model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dense(neurons, activation = activation, kernel_initializer = initializer))\n",
    "    if BN: model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer = keras.optimizers.Nadam(lr=lr))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b546c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_BN = build_model(BN=False, lr=0.001, \n",
    "                     neurons=100, layerz=20, activation='elu', initializer='he_normal')\n",
    "# Default lr on Nadam is 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "270e80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 12s 8ms/step - loss: 2.4103 - accuracy: 0.1815 - val_loss: 1.9752 - val_accuracy: 0.2990\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8913 - accuracy: 0.3117 - val_loss: 1.9911 - val_accuracy: 0.3102\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8114 - accuracy: 0.3473 - val_loss: 1.7998 - val_accuracy: 0.3634\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7600 - accuracy: 0.3685 - val_loss: 1.7249 - val_accuracy: 0.3897\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7085 - accuracy: 0.3880 - val_loss: 1.6542 - val_accuracy: 0.4104\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6712 - accuracy: 0.4002 - val_loss: 1.6679 - val_accuracy: 0.4097\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6368 - accuracy: 0.4193 - val_loss: 1.7388 - val_accuracy: 0.3634\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6172 - accuracy: 0.4258 - val_loss: 1.6219 - val_accuracy: 0.4366\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5960 - accuracy: 0.4347 - val_loss: 1.6338 - val_accuracy: 0.4208\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5712 - accuracy: 0.4392 - val_loss: 1.5783 - val_accuracy: 0.4341\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 3.4849 - accuracy: 0.4391 - val_loss: 1.9005 - val_accuracy: 0.2991\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.9037 - accuracy: 0.2987 - val_loss: 1.8486 - val_accuracy: 0.3161\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8216 - accuracy: 0.3270 - val_loss: 1.7995 - val_accuracy: 0.3406\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7369 - accuracy: 0.3648 - val_loss: 1.7200 - val_accuracy: 0.3769\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6937 - accuracy: 0.3848 - val_loss: 1.7553 - val_accuracy: 0.3537\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6654 - accuracy: 0.3934 - val_loss: 1.6540 - val_accuracy: 0.4059\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6488 - accuracy: 0.4003 - val_loss: 1.6441 - val_accuracy: 0.4075\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6260 - accuracy: 0.4111 - val_loss: 1.6426 - val_accuracy: 0.4108\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5786 - accuracy: 0.4259 - val_loss: 1.5812 - val_accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5578 - accuracy: 0.4350 - val_loss: 1.6105 - val_accuracy: 0.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x160bdf159a0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_BN.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100,\n",
    "                callbacks = [keras.callbacks.EarlyStopping(patience=10), keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87ad9f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6107 - accuracy: 0.4202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.420199990272522"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_BN.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08f07e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 13s 8ms/step - loss: 2.1250 - accuracy: 0.2267 - val_loss: 1.8436 - val_accuracy: 0.3470\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.7585 - accuracy: 0.3608 - val_loss: 1.6857 - val_accuracy: 0.3962\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6496 - accuracy: 0.4054 - val_loss: 1.5984 - val_accuracy: 0.4248\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.5857 - accuracy: 0.4316 - val_loss: 1.5913 - val_accuracy: 0.4186\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.5293 - accuracy: 0.4491 - val_loss: 1.5582 - val_accuracy: 0.4456\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4883 - accuracy: 0.4650 - val_loss: 1.5018 - val_accuracy: 0.4684\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.4427 - accuracy: 0.4821 - val_loss: 1.5208 - val_accuracy: 0.4610\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4127 - accuracy: 0.4939 - val_loss: 1.5152 - val_accuracy: 0.4601\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.3809 - accuracy: 0.5051 - val_loss: 1.4652 - val_accuracy: 0.4866\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3478 - accuracy: 0.5181 - val_loss: 1.5188 - val_accuracy: 0.4592\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3245 - accuracy: 0.5279 - val_loss: 1.4668 - val_accuracy: 0.4794\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.3009 - accuracy: 0.5355 - val_loss: 1.4593 - val_accuracy: 0.4782\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.2731 - accuracy: 0.5454 - val_loss: 1.4839 - val_accuracy: 0.4782\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.2499 - accuracy: 0.5485 - val_loss: 1.4664 - val_accuracy: 0.4888\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2231 - accuracy: 0.5634 - val_loss: 1.4944 - val_accuracy: 0.4831\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2132 - accuracy: 0.5661 - val_loss: 1.4464 - val_accuracy: 0.4984\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1847 - accuracy: 0.5709 - val_loss: 1.4805 - val_accuracy: 0.4873\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1632 - accuracy: 0.5846 - val_loss: 1.4631 - val_accuracy: 0.4918\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1399 - accuracy: 0.5949 - val_loss: 1.4561 - val_accuracy: 0.5055\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1194 - accuracy: 0.5986 - val_loss: 1.4695 - val_accuracy: 0.5001\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0921 - accuracy: 0.6104 - val_loss: 1.4577 - val_accuracy: 0.4985\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0742 - accuracy: 0.6164 - val_loss: 1.4774 - val_accuracy: 0.5075\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0664 - accuracy: 0.6150 - val_loss: 1.4989 - val_accuracy: 0.4968\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0415 - accuracy: 0.6255 - val_loss: 1.5560 - val_accuracy: 0.4861\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0214 - accuracy: 0.6303 - val_loss: 1.5331 - val_accuracy: 0.5030\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0079 - accuracy: 0.6390 - val_loss: 1.5258 - val_accuracy: 0.5018\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5247 - accuracy: 0.4942\n",
      "[(0.4941999912261963, 0.0002)]\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 12s 8ms/step - loss: 2.2181 - accuracy: 0.2150 - val_loss: 1.8415 - val_accuracy: 0.3257\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8181 - accuracy: 0.3417 - val_loss: 1.7414 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7051 - accuracy: 0.3859 - val_loss: 1.6335 - val_accuracy: 0.4172\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6249 - accuracy: 0.4185 - val_loss: 1.6435 - val_accuracy: 0.4152\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5786 - accuracy: 0.4343 - val_loss: 1.5955 - val_accuracy: 0.4350\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5318 - accuracy: 0.4521 - val_loss: 1.5974 - val_accuracy: 0.4373\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4917 - accuracy: 0.4650 - val_loss: 1.5522 - val_accuracy: 0.4434\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4494 - accuracy: 0.4780 - val_loss: 1.5101 - val_accuracy: 0.4604\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4233 - accuracy: 0.4952 - val_loss: 1.5437 - val_accuracy: 0.4483\n",
      "Epoch 10/100\n",
      " 675/1250 [===============>..............] - ETA: 4s - loss: 1.3998 - accuracy: 0.4955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-38bbed9fce64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     model = build_model(BN=False, lr=k/10**4, \n\u001b[0;32m      4\u001b[0m                      neurons=100, layerz=20, activation='elu', initializer='he_normal')\n\u001b[1;32m----> 5\u001b[1;33m     model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100,\n\u001b[0m\u001b[0;32m      6\u001b[0m                 callbacks = [keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0;32m      7\u001b[0m     \u001b[0mevals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evals = []\n",
    "for k in range(2, 5):\n",
    "    model = build_model(BN=False, lr=k/10**4, \n",
    "                     neurons=100, layerz=20, activation='elu', initializer='he_normal')\n",
    "    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100,\n",
    "                callbacks = [keras.callbacks.EarlyStopping(patience=10)])\n",
    "    evals.append((model.evaluate(X_test, y_test)[1], k/10**4))\n",
    "    print(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "973bfdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10000000149011612, 0.1),\n",
       " (0.10000000149011612, 0.01),\n",
       " (0.3806999921798706, 0.001),\n",
       " (0.4918999969959259, 0.0001),\n",
       " (0.490200012922287, 0.0001),\n",
       " (0.48590001463890076, 1e-05),\n",
       " (0.4327000081539154, 1e-06),\n",
       " (0.4941999912261963, 0.0002)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_no_BN = evals1 # ==> best lr is 2/10**4\n",
    "evals_no_BN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae46aa",
   "metadata": {},
   "source": [
    "## Now using batch norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de4a0768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 21s 11ms/step - loss: 2.0670 - accuracy: 0.2576 - val_loss: 1.7961 - val_accuracy: 0.3603\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7834 - accuracy: 0.3657 - val_loss: 1.7436 - val_accuracy: 0.3779\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.7106 - accuracy: 0.3921 - val_loss: 1.6809 - val_accuracy: 0.3923\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.6451 - accuracy: 0.4120 - val_loss: 1.6209 - val_accuracy: 0.4291\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.6134 - accuracy: 0.4269 - val_loss: 1.6207 - val_accuracy: 0.4256\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.5650 - accuracy: 0.4461 - val_loss: 1.5441 - val_accuracy: 0.4598\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.5279 - accuracy: 0.4622 - val_loss: 1.5103 - val_accuracy: 0.4669\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.4893 - accuracy: 0.4777 - val_loss: 1.4518 - val_accuracy: 0.4897\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.4597 - accuracy: 0.4840 - val_loss: 1.4634 - val_accuracy: 0.4782\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.4289 - accuracy: 0.5019 - val_loss: 1.4263 - val_accuracy: 0.4991\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3955 - accuracy: 0.5121 - val_loss: 1.4685 - val_accuracy: 0.4904\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3757 - accuracy: 0.5192 - val_loss: 1.4296 - val_accuracy: 0.5135\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3510 - accuracy: 0.5266 - val_loss: 1.4242 - val_accuracy: 0.5017\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3141 - accuracy: 0.5392 - val_loss: 1.4283 - val_accuracy: 0.5061\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2957 - accuracy: 0.5482 - val_loss: 1.4747 - val_accuracy: 0.4968\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2891 - accuracy: 0.5479 - val_loss: 1.4576 - val_accuracy: 0.5090\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2725 - accuracy: 0.5542 - val_loss: 1.3657 - val_accuracy: 0.5173\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2500 - accuracy: 0.5640 - val_loss: 1.4071 - val_accuracy: 0.5092\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2273 - accuracy: 0.5701 - val_loss: 1.4391 - val_accuracy: 0.5080\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2081 - accuracy: 0.5778 - val_loss: 1.4514 - val_accuracy: 0.4999\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1886 - accuracy: 0.5846 - val_loss: 1.4243 - val_accuracy: 0.5209\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1745 - accuracy: 0.5862 - val_loss: 1.4399 - val_accuracy: 0.5091\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1680 - accuracy: 0.5917 - val_loss: 1.4347 - val_accuracy: 0.5144\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1419 - accuracy: 0.6016 - val_loss: 1.4155 - val_accuracy: 0.5213\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1413 - accuracy: 0.6029 - val_loss: 1.4639 - val_accuracy: 0.5101\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1258 - accuracy: 0.6034 - val_loss: 1.4095 - val_accuracy: 0.5267\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.1316 - accuracy: 0.6022 - val_loss: 1.4609 - val_accuracy: 0.5132\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4674 - accuracy: 0.5097\n",
      "[(0.5097000002861023, 0.003)]\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 21s 10ms/step - loss: 2.1196 - accuracy: 0.2411 - val_loss: 2.0425 - val_accuracy: 0.3022\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.8250 - accuracy: 0.3398 - val_loss: 1.8216 - val_accuracy: 0.3777\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7316 - accuracy: 0.3798 - val_loss: 1.7263 - val_accuracy: 0.3877\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.6679 - accuracy: 0.4049 - val_loss: 1.6772 - val_accuracy: 0.4018\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.6195 - accuracy: 0.4271 - val_loss: 1.6509 - val_accuracy: 0.4155\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 14s 12ms/step - loss: 1.5790 - accuracy: 0.4420 - val_loss: 1.5294 - val_accuracy: 0.4524\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5451 - accuracy: 0.4554 - val_loss: 1.5330 - val_accuracy: 0.4620\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5044 - accuracy: 0.4659 - val_loss: 1.6995 - val_accuracy: 0.4345\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.4763 - accuracy: 0.4772 - val_loss: 1.6225 - val_accuracy: 0.4557\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.4370 - accuracy: 0.4953 - val_loss: 1.5122 - val_accuracy: 0.4857\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.4097 - accuracy: 0.5057 - val_loss: 1.6702 - val_accuracy: 0.4388\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3793 - accuracy: 0.5131 - val_loss: 1.5755 - val_accuracy: 0.4699\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3616 - accuracy: 0.5220 - val_loss: 1.5715 - val_accuracy: 0.4519\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3284 - accuracy: 0.5359 - val_loss: 1.5203 - val_accuracy: 0.4743\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3245 - accuracy: 0.5379 - val_loss: 1.5141 - val_accuracy: 0.4778\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2959 - accuracy: 0.5466 - val_loss: 1.4815 - val_accuracy: 0.4970\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2786 - accuracy: 0.5492 - val_loss: 1.4626 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2582 - accuracy: 0.5579 - val_loss: 1.5608 - val_accuracy: 0.4760\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2326 - accuracy: 0.5648 - val_loss: 1.9081 - val_accuracy: 0.4441\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2288 - accuracy: 0.5699 - val_loss: 1.4411 - val_accuracy: 0.5028\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2046 - accuracy: 0.5786 - val_loss: 1.5215 - val_accuracy: 0.4793\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2049 - accuracy: 0.5765 - val_loss: 1.6126 - val_accuracy: 0.4654\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.1776 - accuracy: 0.5876 - val_loss: 1.5752 - val_accuracy: 0.4664\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1854 - accuracy: 0.5843 - val_loss: 27917946.0000 - val_accuracy: 0.5008\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1583 - accuracy: 0.5988 - val_loss: 1.4206 - val_accuracy: 0.5080\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1459 - accuracy: 0.5986 - val_loss: 1.4621 - val_accuracy: 0.4999\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.1418 - accuracy: 0.5964 - val_loss: 1.6094 - val_accuracy: 0.4568\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1274 - accuracy: 0.6054 - val_loss: 1.4410 - val_accuracy: 0.5053\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1109 - accuracy: 0.6083 - val_loss: 1.6257 - val_accuracy: 0.4676\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.1037 - accuracy: 0.6097 - val_loss: 1.7571 - val_accuracy: 0.4002\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.1035 - accuracy: 0.6128 - val_loss: 1.4711 - val_accuracy: 0.5113\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.0841 - accuracy: 0.6214 - val_loss: 1.4674 - val_accuracy: 0.5087\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.0774 - accuracy: 0.6219 - val_loss: 1.5502 - val_accuracy: 0.4866\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.0768 - accuracy: 0.6217 - val_loss: 1.5188 - val_accuracy: 0.5073\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.0635 - accuracy: 0.6272 - val_loss: 1.5323 - val_accuracy: 0.4980\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5399 - accuracy: 0.4981\n",
      "[(0.5097000002861023, 0.003), (0.49810001254081726, 0.005)]\n"
     ]
    }
   ],
   "source": [
    "evals = []\n",
    "for k in range(3, 6, 2):\n",
    "    model = build_model(BN=True, lr=k/10**3, \n",
    "                     neurons=100, layerz=20, activation='elu', initializer='he_normal')\n",
    "    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100,\n",
    "                callbacks = [keras.callbacks.EarlyStopping(patience=10)])\n",
    "    evals.append((model.evaluate(X_test, y_test)[1], k/10**3))\n",
    "    print(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01b29737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5238000154495239, 0.001),\n",
       " (0.5127999782562256, 0.0001),\n",
       " (0.5097000002861023, 0.003),\n",
       " (0.49810001254081726, 0.005),\n",
       " (0.5097000002861023, 0.003),\n",
       " (0.49810001254081726, 0.005)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_BN ==>  # 0.001 is best lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09217ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
