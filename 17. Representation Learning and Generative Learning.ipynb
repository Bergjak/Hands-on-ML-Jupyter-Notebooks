{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66306f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f391d3c",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "are ANNs that are trained to reproduce their inputs. Autoencoders often do this by compressing the inputs, and so they can generate lossy outputs sometimes. Further, autoencoders are trained without supervision (the training data isn't labeled). Autoencoders can also generate outputs that are similar to their training data rather than just replicating their inputs. So, autoencoders can be used for compression and generating outputs similar to inputs, though these outputs tend to be low quality. However, **Generative Adversarial Networks (GANs)** are the newest form of autoencoder, and they generate amazingly detailed images. GANs work by having a generator and a discriminator. The discriminator is like a typical neural network that learns how to recognize training data, whereas the generator generates outputs that look like the training data but are not, and so tries to trick the discriminator into believing lies, namely that the outputs from the generator are training data. So, the discriminator and generator are enganged in an arms race that is propelled forward by their ability to lean, respectively, how to not be fooled and how to fool.\n",
    "\n",
    "Autoencoders are less sophisticated, in that they simply learn to copy their inputs to their outputs. However, this process is made more diffcult, and the outputs more interesting, by imposing constraints on the autoencoder. For example, we may require that the representations that the autoencoder learns are of a limited size, so that the autoencoder is forced to compress the data. Thus, autoencoders can be thought of as ANNs that learn the identity function under the imposition of various constraints. The representations of the input data that the autoencoders learn are dense representations called **codings** or **latent representations**.\n",
    "\n",
    "Autoencoders always consist of two components: an encoder (aka recognition network) and a decoder. The encoder is in the business of learning the latent representation and the decoder interprets the latent representation. The hope is that the autoencoder discovers and interprets a program that takes less space than simply recapitulating the input data, say in the form of a look-up table. Further, autoencoder output layers always have the same number of dimensions (nodes) as their input. So, for example, if we have an autoencoder with 3 inputs, then it will also have 3 outputs. The simple example given in the text is of a single hidden layer MLP that has two hidden units, 3 inputs and 3 outputs. By having less dimensions in the hidden layer, this constraint forces the autoencoder to learn a latent representation, and an interpretation of it, that does not consist in simply copying the input data. So, the hope is that the autoencoder can discover the two most important dimensions of the input data and then extract from those dimensions the actual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fef50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can implement PCA with a very simple autoencoder.\n",
    "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
    "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
    "PCA_autoencoder = keras.models.Sequential([encoder, decoder])   # We can use full models as layers in other models\n",
    "# So, this is an autoencoder that takes in 3d input, encodes the input into\n",
    "# a 2d representation (the two leading principal components, if we use MSE as the loss function), and\n",
    "# then returns the two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde164a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_autoencoder.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d68060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that X_train is what we train on and what we predict!\n",
    "history = autoencoder.fit(X_train, X_train, epochs = 20)\n",
    "codings = encoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065a9c9",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "consist of two components: a generator and a discriminator, which are trained separately in disjoint steps. Thus, we can conceive of a GANs training process as a two-part cycle, namely (1) the training of the discriminator and (2) training of the generator. The reason we can think of these parts as being disjoint is that the weights of the generator are not updated during the first part and the weights of the discriminator are not updated during the second part.\n",
    "\n",
    "So, what does the training actually consist of? First, the discriminator is trained to classify images. The set of images that the classifier is dealing with comes from two sources, namely a training set of \"real\" images from humans (real <==> labeled 1) and a set of \"fake\" (labeled 0) images made by the generator. In the first step, the discriminator is trained to recognize whether images are real or fake, and only the discriminator has its weights updated using the binary cross entropy loss function. In the second step, the discriminator is exposed only to images made by the generator, and every such image is labeled as real (i.e., labeled 1); the generator is rewarded for getting the discriminator to predict that the images are real and punished for predicting that the images are fake, wherein only the weights of the generator are updated during this step. Eventually, this allows the generator to get really good at making images that look realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47ea23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 30\n",
    "\n",
    "generator = keras.models.Sequential([keras.layers.Dense(100, activation='selu', input_shape=[codings_size]),\n",
    "                                    keras.layers.Dense(150, activation='selu'),\n",
    "                                    keras.layers.Dense(28*28, activation='sigmoid'),\n",
    "                                    keras.layers.Reshape([28, 28])])\n",
    "\n",
    "discriminator = keras.models.Sequential([keras.layers.Flatten(input_shape=[28, 28]),\n",
    "                                        keras.layers.Dense(150, activation='selu'),\n",
    "                                        keras.layers.Dense(100, activation='selu'),\n",
    "                                        keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb73da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we compile the models and make the discriminator not trainable for the second phase\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc72a2b",
   "metadata": {},
   "source": [
    "\"Note: The trainable attribute is taken into account by Keras only when compiling a model, so after running this code, the discriminator *is* trainable if we call its fit() method or its train_on_batch() method (which we will be using), while it is *not* trainable when we call these methods on the gain model.\" So, setting the trainable attribute to false just ensures that we are not training during the second step, but changes nothing for the first step, which is just what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa416ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d404d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f22b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write a special function for training the gan:\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs = 50): \n",
    "    generator, discriminator = gan.layers \n",
    "    for epoch in range(n_epochs): \n",
    "        for X_batch in dataset: \n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape = [batch_size, codings_size]) \n",
    "            generated_images = generator(noise) \n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0) \n",
    "            y1 = tf.constant([[ 0.]] * batch_size + [[ 1.]] * batch_size) \n",
    "            discriminator.trainable = True \n",
    "            discriminator.train_on_batch(X_fake_and_real, y1) \n",
    "            # phase 2 - training the generator \n",
    "            noise = tf.random.normal(shape = [batch_size, codings_size])\n",
    "            y2 = tf.constant([[ 1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf66134",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute ConcatV2 as input #1(zero-based) was expected to be a float tensor but is a uint8 tensor [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dce3399abadd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_gan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodings_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-3d6f44d57db6>\u001b[0m in \u001b[0;36mtrain_gan\u001b[1;34m(gan, dataset, batch_size, codings_size, n_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodings_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mX_fake_and_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1675\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1676\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1677\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1190\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1193\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakob berg\\ml_path\\my_env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute ConcatV2 as input #1(zero-based) was expected to be a float tensor but is a uint8 tensor [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d178ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
