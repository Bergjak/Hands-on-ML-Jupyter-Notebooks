{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d901c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceb9159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train)\n",
    "X_valid = scaler.transform( X_valid)\n",
    "X_test = scaler.transform( X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e751db",
   "metadata": {},
   "source": [
    "# Tensorflow:\n",
    "Tensorflow is a library made by Google Brain researchers. Its purpose is to optimize large scale computations and to allow programs coded in one environment (e.g., java, python, Ruby, C++, etc.) to be ran in another. This is primarily done by Tensorflow's ability to extract a **computation graph** of the Python function being ran. The computation graph consists of nodes (tasks to be done) and edges (the tasks that are pursued as a consequence of which nodes are active). Unused nodes are then pruned from the computation graph, which speeds up the runtime. Furthermore, this computation graph can be implemented in other languages, and so allows the Essence of a program to be realized by other languages. Finally, independent paths of the computation graph can be ran in parallel, which further speeds up runtime. I visualize, initially, a graph with many unused nodes on the periphery, which then fade away (are pruned), and independent paths, which are traversed (computed) at the same time. Also, it optimizes for GPU operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4357946",
   "metadata": {},
   "source": [
    "# Using Tensorflow like Numpy:\n",
    "Tensorflow has many operations that are very similar to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4cc1c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0d349f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32, TensorShape([2, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82f433ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fec78167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 4.],\n",
       "       [2., 5.],\n",
       "       [3., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6491955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t) == tf.matmul(t, tf.transpose(t))  # The @ operator is matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fca62f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=bool, numpy=\n",
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t + t)**2 == (2*t * 2*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25ad9d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=21.0>, True, 21)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(t), np.sum(t) == 21, 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f765643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.5>, True, 3.5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(t), np.mean(t) == 3.5, 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13f30a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, 6.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(t),  np.max(t)   # Notice that both find the max in the entire data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91205138",
   "metadata": {},
   "source": [
    "**Type Conversions**: Changing the data type of an array is slow, and so tensorflow does not allow for operations inolving two tensors of diffferent datatypes. For example, if x and y are tensors such that x is float16 and y is float32 (or an int16, int8, int whatever, etc.), then you get an error for trying to do any operation on x and y. This speeds up performance. However, if you need to change the datatype of some tensor, then you can say, tf.cast(x, dtype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0abb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[112. 105.]\n",
      " [ 52.  48.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# For example,\n",
    "x = tf.constant([[5, 6], [2, 3.0]], dtype='float32')\n",
    "y = tf.constant([[8, 9], [12, 10]], dtype='int8')\n",
    "print(x @ tf.cast(y, 'float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e669f4",
   "metadata": {},
   "source": [
    "**Modifying Tensor contents**: With tensors (that is, tf.constant), we cannot modify them. However, if we make tf.Variable, then we get a tensor that can be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a940ebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[1,2,3], [4,5,6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e09f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[  1, 100,   3],\n",
       "       [  4, 100,   6]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1].assign([100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97566e8",
   "metadata": {},
   "source": [
    "# Customizing Models and Training Algorithms:\n",
    "Say you are training a regression MLP and your dataset, even after being cleaned, has many outliers. What we can do about this is choose a good loss function. MSE will be too sensitive too the outliers, which is bad. MAE will be less sensitive to the outliers, but will take a longer time to converge and yield a less precise model. So, a good solution would be somewhere inbetween MSE and MAE, which is what the Huber loss function does. The Huber loss function rewards predictions that give errors that are less than some pre-selected threshold.\n",
    "\n",
    "**Notice** that when we implement the loss function, we use tf commands and use vectorized data structures. We do this because we therefore get performance enhancements from TensorFlow, such as being able to use the GPU support and the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "810cbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1 # This gives a vector of bools\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "        # if error is small, we return squared loss. If not, return linear loss\n",
    "        # This causes the error gradient to arise primarily from the parameters that are giving linear losses, since losses that\n",
    "        # are less than threshold (here, 1) are made even smaller by being squared, and so thoses losses are relatively ignored\n",
    "        # and so the linear errors are focused on. This intuitively suggests that the model will minimize loss by ignoring\n",
    "        # outliers (since it's hopeless to get their loss to be squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ae4262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.003e-02 1.500e+00 1.984e-02 3.550e+01 6.500e+00], shape=(5,), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3, 4, 5], dtype='float16')\n",
    "b = tf.constant([1.2, 4, 2.8, 40, 12], dtype='float16')\n",
    "\n",
    "print(huber_fn(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d9df6",
   "metadata": {},
   "source": [
    "Now, we can use the huber loss function to train a network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4f7d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', input_shape=(X_train.shape[1:]), kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d8cff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=keras.optimizers.RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7c30f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.1858\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.1938 - val_loss: 0.1588\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.1764 - val_loss: 0.1792\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.1657 - val_loss: 0.1419\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.1541 - val_loss: 0.1727\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.1471 - val_loss: 0.1712\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.1478 - val_loss: 0.1443\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.1432 - val_loss: 0.1446\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.1447 - val_loss: 0.1444\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.1365 - val_loss: 0.1302\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.1336 - val_loss: 0.1243\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.1363 - val_loss: 0.1263\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.1256 - val_loss: 0.1263\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.1270 - val_loss: 0.1275\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.1253 - val_loss: 0.1250\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.1240 - val_loss: 0.1207\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.1219 - val_loss: 0.1335\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.1298 - val_loss: 0.1205\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.1223 - val_loss: 0.1186\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.1190 - val_loss: 0.1286\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.1175 - val_loss: 0.1221\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.1214 - val_loss: 0.1279\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.1177 - val_loss: 0.1190\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.1196 - val_loss: 0.1202\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.1183 - val_loss: 0.1215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x254b5cba3a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b17bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72513dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 453us/step - loss: 0.1285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12845680117607117"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62f0b9",
   "metadata": {},
   "source": [
    "**Custom Activation Functions, Initializers, Regularizers, and Constraints** are implemented in the same way as custom loss functions: We simply write the function and then plug it into the appropriate part of the model, such as when we wrote \"loss=huber_fn\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e06cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
